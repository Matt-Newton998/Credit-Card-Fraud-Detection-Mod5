{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Functions\n",
    "from Credit_Func import *\n",
    "\n",
    "# Import the Basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Other\n",
    "import pickle\n",
    "\n",
    "# Model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matix(y_val, y_pred, classes, model_name=None):\n",
    "    import itertools\n",
    "    \n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    print('\\n clasification report:\\n', classification_report(y_val,y_pred))\n",
    "    print(\"-----------------------------------------------\")\n",
    "    print(f\"Accuracy: {round(accuracy*100,3)}%\")\n",
    "    print(f\"Precision: {round(precision*100,3)}%\")\n",
    "    print(f\"Recall: {round(recall*100,3)}%\")\n",
    "    print(f\"f1_score: {round(f1*100,3)}%\")\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    print(f\"Frauds: {y_val.sum()} | Missed: {round((cnf_matrix[1][0]/y_val.sum())*100,1)}%\")\n",
    "    \n",
    "    # Create the basic matrix\n",
    "    plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) \n",
    "\n",
    "    # Add title and axis labels\n",
    "    plt.title(f'{model_name} Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    # Add appropriate axis scales\n",
    "    class_names = ['',classes[0],'',classes[1],'']# set(y) # Get class labels to add to matrix\n",
    "    tick_marks = [-0.5,0,0.5,1,1.5]\n",
    "    \n",
    "    # Add appropriate axis scales\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Add labels to each cell\n",
    "    thresh = cnf_matrix.max() / 2. # Used for text coloring below\n",
    "    # Here we iterate through the confusion matrix and append labels to our visualization \n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "            plt.text(j, i, cnf_matrix[i, j],\n",
    "                     horizontalalignment='center',\n",
    "                     color='white' if cnf_matrix[i, j] > thresh else 'black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = df['Time']\n",
    "new_time = []\n",
    "for d in time:\n",
    "    if d <= 86400:     # There are 86400 seconds in a day\n",
    "        new_time.append(d)\n",
    "    else:\n",
    "        new_time.append(d - 86400)\n",
    "        \n",
    "df['Time'] = new_time      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Class\n",
    "\n",
    "X = df.drop(columns=['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shapes:\n",
      "X_tv: (199364, 30) | X_test: (85443, 30) | y_tv (199364,) | y_test (85443,)\n",
      "Number of Frauds in TV: 356 | 0.17857%\n",
      "Number of Frauds in Test: 136 | 0.15917%\n"
     ]
    }
   ],
   "source": [
    "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Data Shapes:\")\n",
    "print(f\"X_tv: {X_tv.shape} | X_test: {X_test.shape} | y_tv {y_tv.shape} | y_test {y_test.shape}\")\n",
    "print(f\"Number of Frauds in TV: {y_tv.sum()} | {round((y_tv.sum() / y_tv.shape[0])*100, 5)}%\")\n",
    "print(f\"Number of Frauds in Test: {y_test.sum()} | {round((y_test.sum() / y_test.shape[0])*100, 5)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (139554, 30) | X_val: (59810, 30) | y_train (139554,) | y_val (59810,)\n",
      "Number of Frauds in Train: 258 | 0.18487%\n",
      "Number of Frauds in Validation: 98 | 0.16385%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_tv, y_tv, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"X_train: {X_train.shape} | X_val: {X_val.shape} | y_train {y_train.shape} | y_val {y_val.shape}\")\n",
    "print(f\"Number of Frauds in Train: {y_train.sum()} | {round((y_train.sum() / y_train.shape[0])*100, 5)}%\")\n",
    "print(f\"Number of Frauds in Validation: {y_val.sum()} | {round((y_val.sum() / y_val.shape[0])*100, 5)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.0\n",
      "standard dev:  1.0\n",
      "mean:  -0.0\n",
      "standard dev:  1.0\n",
      "mean:  0.0\n",
      "standard dev:  0.99\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_Val_transformed = scaler.transform(X_val)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "trans = [X_train_transformed, X_Val_transformed, X_test_transformed]\n",
    "\n",
    "for X in trans:\n",
    "    print((\"mean: \"), np.round(X.mean(), 2))\n",
    "    print((\"standard dev: \"), np.round(X.std(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset data\n",
    "X_train = X_train_transformed\n",
    "X_val = X_Val_transformed\n",
    "X_test = X_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class distribution:\n",
      "0    139296\n",
      "1       258\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "\n",
      "SMOTE_even class distribution\n",
      "1    139296\n",
      "0    139296\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Previous original class distribution\n",
    "print(\"original class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Fit SMOTE to training data\n",
    "smote = SMOTE(sampling_strategy='auto') # resample all classes but the majority class\n",
    "X_train_smote, y_train_smote = smote.fit_sample(X_train, y_train) \n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('\\n')\n",
    "print(\"SMOTE_even class distribution\")\n",
    "print(pd.Series(y_train_smote).value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original class distribution:\n",
      "0    139296\n",
      "1       258\n",
      "Name: Class, dtype: int64\n",
      "\n",
      "\n",
      "ADASYN class distribution\n",
      "1    139323\n",
      "0    139296\n",
      "Name: Class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Previous original class distribution\n",
    "print(\"original class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "# Fit SMOTE to training data\n",
    "adasyn = ADASYN(sampling_strategy='auto') # resample all classes but the majority class\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_sample(X_train, y_train) \n",
    "\n",
    "# Preview synthetic sample class distribution\n",
    "print('\\n')\n",
    "print(\"ADASYN class distribution\")\n",
    "print(pd.Series(y_train_adasyn).value_counts()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct pipeline\n",
    "pipe_knn = Pipeline([('clf', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 372.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=1,\n",
       "             param_grid=[{'metric': ['manhattan', 'euclidean'],\n",
       "                          'n_neighbors': [3, 5, 11, 19]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set grid search params\n",
    "param_grid_knn = [{'n_neighbors': [3, 5, 11, 19], \n",
    "                   #'weight': ['uniform', 'distance'],\n",
    "                   'metric': ['manhattan', 'euclidean'],\n",
    "                   #'p':[1, 2] \n",
    "                  }]\n",
    "\n",
    "# Construct grid search\n",
    "gs_knn = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "            param_grid=param_grid_knn,\n",
    "           # scoring='roc_auc',\n",
    "            cv=3, verbose=1, return_train_score = True, n_jobs=1)\n",
    "\n",
    "# Fit the model\n",
    "gs_knn.fit(X_train_smote, y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(gs_knn, 'knn_model_final.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_knn = GS_Output_DataFrame(gs_knn)\n",
    "opt_knn.sort_values(by='mean_test_score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gs_knn.best_estimator_\n",
    "print(gs_xg.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_val)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = best_model.predict_proba(X_val)\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matix(y_val, y_pred, ['Normal', \"Fraud\"], \"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_plot(model,X_train_smote,y_train_smote,X_val,y_val):\n",
    "    train_prob = model.predict_proba(X_train)[:,1]\n",
    "    val_prob = model.predict_proba(X_val)[:,1]\n",
    "    plt.figure(figsize=(7,7))\n",
    "    for data in [[y_train, train_prob],[y_val, val_prob]]: # ,[y_test, test_prob]\n",
    "        fpr, tpr, threshold = roc_curve(data[0], data[1])\n",
    "        plt.plot(fpr, tpr)\n",
    "    annot(fpr, tpr, threshold)\n",
    "    plt.plot([0, 1], [0, 1], color='black', linestyle='--')\n",
    "    plt.ylabel('TPR (power)')\n",
    "    plt.xlabel('FPR (alpha)')\n",
    "    plt.legend(['train','val'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_plot(best_model, X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(best_model.feature_importances_, index=[X_tv.columns], columns=['Importance'])\n",
    "features = features.loc[features['Importance'] != 0]\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model, X):\n",
    "    n_features = X.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.title('Feature Importance XGBoost', fontsize=18)\n",
    "\n",
    "plot_feature_importances(best_model, X_tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_val, y_pred)\n",
    "print(fpr, tpr, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_val, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevalence = df['Class'].sum()/df.shape[0]\n",
    "fraud_cost_coef = 122.21132113821139\n",
    "normal_cost_coef = 88.29102242231328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = roc_curve(y_val, y_prob[:,1])\n",
    "fpr, tpr, threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treshold_selection(prevalence, mean_cost_fraud, mean_cost_Nfraud, y_val, y_pred):\n",
    "    fpr, tpr, threshold = roc_curve(y_val, y_pred)\n",
    "    cnf_matrix = confusion_matrix(y_val, y_pred)\n",
    "    TP, FP, FN, TN = cnf_matrix[0][0], cnf_matrix[0][1], cnf_matrix[1][0], cnf_matrix[1][1]\n",
    "    \n",
    "    m = ((1-prevalence)/prevalence) * ((mean_cost_Nfraud*(FP - TN))/(mean_cost_fraud*(FN - TP)))\n",
    "    \n",
    "    fm = tpr - (m * fpr)\n",
    "    \n",
    "    opt = pd.DataFrame(data=fm)\n",
    "    \n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold_selection(prevalence, fraud_cost_coef, normal_cost_coef, y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
